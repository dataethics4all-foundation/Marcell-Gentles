{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import tkinter as tk\n",
    "import tweepy as tp\n",
    "from IPython.display import display, HTML\n",
    "from trainer import preprocess\n",
    "\n",
    "fake_tweets = [\n",
    "    ('Blah blah blah', )\n",
    "]\n",
    "\n",
    "MODEL_PATH = r'Models\\TFIDF_Logistic Regression_800000_06-13-2023--07-49-51\\Logistic Regression.pkl'\n",
    "VEC_PATH = r'Models\\TFIDF_Logistic Regression_800000_06-13-2023--07-49-51\\TFIDF.pkl'\n",
    "model = joblib.load(MODEL_PATH)\n",
    "vectorizer = joblib.load(VEC_PATH)\n",
    "\n",
    "def get_tweets(\n",
    "        username, max_results = 5,\n",
    "        includingRetweets = False, includingReplies = True\n",
    "        ) -> tuple[str, str]:\n",
    "    \"\"\"Takes a username, a number of results to fetch, and booleans that\n",
    "    indicate whether or not to include retweets and replies, and returns a\n",
    "    list of (tweet, id) tuples.\n",
    "    \"\"\"\n",
    "    # needs a working bearer_token to access to Twitter API\n",
    "    bearer_token = \"redacted\"\n",
    "    # These all seem to be unnecessary.\n",
    "    client_ID = \"redacted\"\n",
    "    client_secret = \"redacted\"\n",
    "    redirect_uri = \"redacted\"\n",
    "    access_token = \"redacted\"\n",
    "    access_token_secret = \"redacted\"\n",
    "    api_key = \"redacted\"\n",
    "    api_secret = \"redacted\"\n",
    "\n",
    "    client = tp.Client(bearer_token=bearer_token)\n",
    "\n",
    "    \"\"\"client = tp.Client(\n",
    "        bearer_token=bearer_token, consumer_key=api_key,\n",
    "        consumer_secret=api_secret, access_token=access_token,\n",
    "        access_token_secret=access_token_secret\n",
    "        )\"\"\"\n",
    "    \n",
    "    ID = client.get_user(username=username).data.id\n",
    "\n",
    "\n",
    "    def choose_exclusions(rt, rp):\n",
    "        \"\"\"Makes a list of things to exclude from get_users_tweets. If\n",
    "        nothing, returns None instead of an empty list because tweepy does\n",
    "        not like the empty list.\"\"\"\n",
    "        lst = []\n",
    "        if not rt:\n",
    "            lst.append('retweets')\n",
    "        if not rp:\n",
    "            lst.append('replies')\n",
    "        if len(lst) == 0: lst = None\n",
    "        return lst\n",
    "\n",
    "    tweets = client.get_users_tweets(\n",
    "        id=ID, max_results=max_results,\n",
    "        exclude=choose_exclusions(includingRetweets, includingReplies)\n",
    "        )\n",
    "    \n",
    "    temp = []\n",
    "    for i in range(len(tweets.data)):\n",
    "        temp.append((tweets.data[i].text, tweets.data[i].id))\n",
    "    \n",
    "    tweet_list = temp\n",
    "    return tweet_list\n",
    "\n",
    "user = input(\"Enter username of target account: \")\n",
    "rt_in = input(\"Would you like to include retweets? \")\n",
    "rp_in = input(\"Would you like to include replies? \")\n",
    "num = int(input(\"How many results would you like to include (max 50)? \"))\n",
    "rt = True if 'y' in rt_in.lower() else False if 'n' in rt_in.lower() else None\n",
    "rp = True if 'y' in rp_in.lower() else False if 'n' in rp_in.lower() else None\n",
    "\n",
    "tweets_n_ids = get_tweets(user, num, rt, rp)\n",
    "tweets = list(i[0] for i in tweets_n_ids)\n",
    "vectorized_docs = vectorizer.transform(preprocess(tweets))\n",
    "predictions = model.predict(vectorized_docs)\n",
    "\n",
    "data = []\n",
    "for i in range(len(predictions)):\n",
    "    data.append(\n",
    "        (\n",
    "        tweets[i],\n",
    "                f'https://twitter.com/twitter/statuses/{tweets_n_ids[i][1]}',\n",
    "                predictions[i]\n",
    "            )\n",
    "        )\n",
    "\n",
    "displaying_as = 'html'    \n",
    "\n",
    "if displaying_as == 'html':\n",
    "    html = []\n",
    "    for i in range(len(predictions)):\n",
    "        html.append(\n",
    "            f'<h3>{predictions[i]}    <a href=\"{data[i][1]}\">{data[i][0]}</a></h3>'\n",
    "            )\n",
    "    html = '\\n'.join(html)\n",
    "    display(HTML(html))\n",
    "\n",
    "elif displaying_as == 'df':\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SiAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
