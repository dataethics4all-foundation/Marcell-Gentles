{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16f0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = 'TFIDF'\n",
    "size = 500\n",
    "retrain = True\n",
    "models = ['nb', 'lr', 'svm']\n",
    "save = True\n",
    "plot = ['table']\n",
    "\n",
    "dataFile = \"training.1600000.processed.noemoticon.csv\"\n",
    "makingCSV = False\n",
    "\n",
    "if ('matrix' in plot or 'table' in plot or save) and not retrain:\n",
    "    raise Exception('Must retrain to take other actions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e5a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "import sklearn.metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f5efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   Label                                               Text  \\\n",
      "0     -1  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
      "1     -1  is upset that he can't update his Facebook by ...   \n",
      "2     -1  @Kenichan I dived many times for the ball. Man...   \n",
      "3     -1    my whole body feels itchy and like its on fire    \n",
      "4     -1  @nationwideclass no, it's not behaving at all....   \n",
      "5      1       I LOVE @Health4UandPets u guys r the best!!    \n",
      "6      1  im meeting up with one of my besties tonight! ...   \n",
      "7      1  @DaRealSunisaKim Thanks for the Twitter add, S...   \n",
      "8      1  Being sick can be really cheap when it hurts t...   \n",
      "9      1    @LovesBrooklyn2 he has that effect on everyone    \n",
      "\n",
      "                                             Cleaned  B: awww  B: bummer  \\\n",
      "0     awww bummer shoulda got david carr third day d        0          0   \n",
      "1  upset updat facebook text might cri result sch...        0          0   \n",
      "2    dive mani time ball manag save 50 rest go bound        1          0   \n",
      "3                    whole bodi feel itchi like fire        0          0   \n",
      "4                                      behav mad see        0          0   \n",
      "5                                    love guy r best        0          0   \n",
      "6              meet one besti tonight wait girl talk        0          0   \n",
      "7  thank twitter add sunisa got meet hin show dc ...        0          1   \n",
      "8  sick can realli cheap hurt much eat real food ...        0          0   \n",
      "9                                     effect everyon        0          0   \n",
      "\n",
      "   B: shoulda  B: got  B: david  B: carr  B: third  ...   T: much    T: eat  \\\n",
      "0           0       0         1        0         0  ...  0.000000  0.359846   \n",
      "1           1       0         0        0         0  ...  0.000000  0.000000   \n",
      "2           0       0         0        1         0  ...  0.000000  0.000000   \n",
      "3           0       0         0        0         0  ...  0.000000  0.000000   \n",
      "4           0       0         0        0         1  ...  0.000000  0.000000   \n",
      "5           0       0         0        0         0  ...  0.000000  0.000000   \n",
      "6           0       0         0        0         0  ...  0.000000  0.000000   \n",
      "7           0       1         0        0         0  ...  0.309414  0.000000   \n",
      "8           0       0         0        0         0  ...  0.000000  0.000000   \n",
      "9           0       0         0        0         0  ...  0.000000  0.000000   \n",
      "\n",
      "    T: real   T: food    T: plu  T: friend   T: make   T: soup  T: effect  \\\n",
      "0  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
      "1  0.000000  0.301511  0.000000   0.000000  0.301511  0.301511   0.000000   \n",
      "2  0.316228  0.000000  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
      "3  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
      "4  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
      "5  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
      "6  0.000000  0.000000  0.385682   0.000000  0.000000  0.000000   0.385682   \n",
      "7  0.000000  0.000000  0.000000   0.309414  0.000000  0.000000   0.000000   \n",
      "8  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
      "9  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   0.000000   \n",
      "\n",
      "   T: everyon  \n",
      "0    0.000000  \n",
      "1    0.000000  \n",
      "2    0.000000  \n",
      "3    0.408248  \n",
      "4    0.000000  \n",
      "5    0.000000  \n",
      "6    0.000000  \n",
      "7    0.000000  \n",
      "8    0.000000  \n",
      "9    0.000000  \n",
      "\n",
      "[10 rows x 147 columns], {'BoW': {'awww': 4, 'bummer': 12, 'shoulda': 54, 'got': 31, 'david': 17, 'carr': 14, 'third': 63, 'day': 18, 'upset': 69, 'updat': 68, 'facebook': 24, 'text': 61, 'might': 43, 'cri': 16, 'result': 50, 'school': 52, 'today': 65, 'also': 2, 'blah': 9, 'dive': 20, 'mani': 41, 'time': 64, 'ball': 5, 'manag': 40, 'save': 51, '50': 0, 'rest': 49, 'go': 30, 'bound': 11, 'whole': 71, 'bodi': 10, 'feel': 25, 'itchi': 35, 'like': 36, 'fire': 26, 'behav': 6, 'mad': 38, 'see': 53, 'love': 37, 'guy': 32, 'best': 7, 'meet': 42, 'one': 45, 'besti': 8, 'tonight': 66, 'wait': 70, 'girl': 29, 'talk': 60, 'thank': 62, 'twitter': 67, 'add': 1, 'sunisa': 58, 'hin': 33, 'show': 55, 'dc': 19, 'area': 3, 'sweetheart': 59, 'sick': 56, 'can': 13, 'realli': 48, 'cheap': 15, 'hurt': 34, 'much': 44, 'eat': 21, 'real': 47, 'food': 27, 'plu': 46, 'friend': 28, 'make': 39, 'soup': 57, 'effect': 22, 'everyon': 23}, 'TFIDF': {'awww': 4, 'bummer': 12, 'shoulda': 54, 'got': 31, 'david': 17, 'carr': 14, 'third': 63, 'day': 18, 'upset': 69, 'updat': 68, 'facebook': 24, 'text': 61, 'might': 43, 'cri': 16, 'result': 50, 'school': 52, 'today': 65, 'also': 2, 'blah': 9, 'dive': 20, 'mani': 41, 'time': 64, 'ball': 5, 'manag': 40, 'save': 51, '50': 0, 'rest': 49, 'go': 30, 'bound': 11, 'whole': 71, 'bodi': 10, 'feel': 25, 'itchi': 35, 'like': 36, 'fire': 26, 'behav': 6, 'mad': 38, 'see': 53, 'love': 37, 'guy': 32, 'best': 7, 'meet': 42, 'one': 45, 'besti': 8, 'tonight': 66, 'wait': 70, 'girl': 29, 'talk': 60, 'thank': 62, 'twitter': 67, 'add': 1, 'sunisa': 58, 'hin': 33, 'show': 55, 'dc': 19, 'area': 3, 'sweetheart': 59, 'sick': 56, 'can': 13, 'realli': 48, 'cheap': 15, 'hurt': 34, 'much': 44, 'eat': 21, 'real': 47, 'food': 27, 'plu': 46, 'friend': 28, 'make': 39, 'soup': 57, 'effect': 22, 'everyon': 23}})\n",
      "return\n",
      "(1000, 5013)\n"
     ]
    }
   ],
   "source": [
    "if retrain:\n",
    "    if not makingCSV:\n",
    "        from CleanTweetsScript import vectorize, clean\n",
    "        (df, doubleVocab) = vectorize(clean(dataFile, size))\n",
    "\n",
    "        print(\"return\")\n",
    "        print(df.shape)\n",
    "\n",
    "    else:\n",
    "        vectorize(clean(dataFile, size), makeCSV= True)\n",
    "        df = pd.read_csv(\"cleaned_data.csv\", index_col=0)\n",
    "        print(\"csv\")\n",
    "\n",
    "\n",
    "    df = df[df.Label != 2]\n",
    "    df = df[pd.notna(df.Label)]\n",
    "\n",
    "    # 3:int((df.shape[1] - 3) / 2)\n",
    "\n",
    "    bow_df = df.iloc[:, 3:int((df.shape[1] - 3) / 2 + 3)]\n",
    "    bow_df = bow_df.reset_index(drop=True)\n",
    "\n",
    "    tfidf_df = df.iloc[:, int((df.shape[1] - 3) / 2 + 3):df.shape[1]]\n",
    "    tfidf_df = tfidf_df.reset_index(drop=True)\n",
    "\n",
    "    sentiment = df.Label.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81ff29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_test = y_train = y_test = nb = nb_pred = lr = lr_pred = svm = svm_pred = timeLog = None \n",
    "#timeLogList = []\n",
    "\n",
    "def fit(rep, refit= True, models=['nb','lr','svm'], save= True, plot= ['table', 'matrix']):\n",
    "    #global x_train, x_test, y_train, y_test, nb, nb_pred, lr, lr_pred, svm, svm_pred, timeLog, timeLogList\n",
    "\n",
    "    print(rep)\n",
    "\n",
    "    if refit == True:\n",
    "        from datetime import datetime\n",
    "        timeLogList = []\n",
    "        print(\"Started at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "        timeLogList.append(\"Started at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "        if rep in [\"BoW\", \"TFIDF\"]:\n",
    "            x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split \\\n",
    "                (bow_df if rep == \"BoW\" else tfidf_df, sentiment, train_size=0.7)\n",
    "            print(\"Split at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            timeLogList.append(\"Split at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "            if 'nb' in models:\n",
    "                nb = sklearn.naive_bayes.MultinomialNB()\n",
    "                nb.fit(x_train, y_train)\n",
    "                nb_pred = nb.predict(x_test)\n",
    "                print(\"Naive Bayes fit at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "                timeLogList.append(\"Naive Bayes fit at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "            if 'lr' in models:\n",
    "                lr = sklearn.linear_model.LogisticRegression()\n",
    "                lr.fit(x_train, y_train)\n",
    "                lr_pred = lr.predict(x_test)\n",
    "                print(\"Logistic Regression fit at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "                timeLogList.append(\"Logistic Regression fit at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "            if 'svm' in models:\n",
    "                svm = sklearn.svm.SVC()\n",
    "                svm.fit(x_train, y_train)\n",
    "                svm_pred = svm.predict(x_test)\n",
    "                print(\"Support Vector Machine fit at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "                timeLogList.append(\"Support Vector Machine fit at \" + datetime.now().strftime(\"%H:%M:%S\"))\n",
    "                timeLog = \"\\n\".join(timeLogList)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Variable \\'model\\' must be \\'BoW\\' or \\'TFIDF\\'.\")\n",
    "        \n",
    "    def metrics(y_true, y_pred):\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "        precision = sklearn.metrics.precision_score(y_true, y_pred)\n",
    "        recall = sklearn.metrics.recall_score(y_true, y_pred)\n",
    "        f1 = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    #for i in [x_train, x_test, y_train, y_test]:\n",
    "    #    print(i)\n",
    "    #    print()\n",
    "\n",
    "    nb_conf_matrix = sklearn.metrics.confusion_matrix(y_test, nb_pred, labels=nb.classes_)\n",
    "    nb_d = metrics(y_test, nb_pred)\n",
    "\n",
    "    lr_conf_matrix = sklearn.metrics.confusion_matrix(y_test, lr_pred, labels=nb.classes_)\n",
    "    lr_d = metrics(y_test, lr_pred)\n",
    "\n",
    "    svm_conf_matrix = sklearn.metrics.confusion_matrix(y_test, svm_pred, labels=nb.classes_)\n",
    "    svm_d = metrics(y_test, svm_pred)\n",
    "\n",
    "\n",
    "    metrics_df = pd.DataFrame([nb_d, lr_d, svm_d], columns= [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"], \\\n",
    "                            index= [\"Naive Bayes\", \"Logistic Regression\", \"Support Vector Machine\"])\n",
    "    \n",
    "    if save == True:\n",
    "        from joblib import dump, load\n",
    "        import os\n",
    "\n",
    "        try:\n",
    "            os.mkdir('models')\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        def saveModel(model, name, size):\n",
    "            try:\n",
    "                os.mkdir(rf'models\\{rep}{size}')\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "            #cd = os.path.dirname(__file__)\n",
    "            cd = rf\"C:\\Users\\marce\\Project\\models\\{rep}{size}\"\n",
    "            newPath = os.path.join(cd, rf'Model_{rep}_{name}_{size}.pkl')\n",
    "            dump(model, newPath)\n",
    "            vocabPath = os.path.join(cd, rf'Vocab_{size}.pkl')\n",
    "            dump(doubleVocab[rep], vocabPath)\n",
    "            statsPath = os.path.join(cd, rf'Metrics_{rep}_{size}.html')\n",
    "            metrics_df.to_html(statsPath)\n",
    "            logPath = os.path.join(cd, rf'TimeLog_{rep}_{size}.txt')\n",
    "            with open(logPath, 'w') as f:\n",
    "                f.write(timeLog)\n",
    "\n",
    "\n",
    "        for model in [(nb, 'NaiveBayes'), (lr, 'LogisticRegression'), (svm, 'SupportVectorMachine')]:\n",
    "            saveModel(model[0], model[1], size)\n",
    "        \n",
    "    if 'table' in plot:\n",
    "        \n",
    "        display(metrics_df)\n",
    "\n",
    "    if 'matrix' in plot:\n",
    "        nb_disp = sklearn.metrics.ConfusionMatrixDisplay(nb_conf_matrix)\n",
    "        nb_disp.plot()\n",
    "        nb_disp.ax_.set_title(\"Naive Bayes\")\n",
    "        #print(f\"Naive Bayes: {metrics(y_test, nb_pred)}\")\n",
    "\n",
    "        lr_disp = sklearn.metrics.ConfusionMatrixDisplay(lr_conf_matrix)\n",
    "        lr_disp.plot()\n",
    "        lr_disp.ax_.set_title(\"Logistic Regression\")\n",
    "        #print(f\"Logistic Regression: {metrics(y_test, lr_pred)}\")\n",
    "\n",
    "        svm_disp = sklearn.metrics.ConfusionMatrixDisplay(svm_conf_matrix)\n",
    "        svm_disp.plot()\n",
    "        svm_disp.ax_.set_title(\"Support Vector Machine\")\n",
    "        #print(f\"Support Vector Machine: {metrics(y_test, svm_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d65f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF\n",
      "Started at 05:40:28\n",
      "Split at 05:40:28\n",
      "Naive Bayes fit at 05:40:28\n",
      "Logistic Regression fit at 05:40:28\n",
      "Support Vector Machine fit at 05:40:29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.639498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.583851</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.630872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.596667</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.603279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall        F1\n",
       "Naive Bayes             0.616667   0.560440  0.744526  0.639498\n",
       "Logistic Regression     0.633333   0.583851  0.686131  0.630872\n",
       "Support Vector Machine  0.596667   0.547619  0.671533  0.603279"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if representation in ('BoW', 'TFIDF'):\n",
    "    fit(representation, retrain, models, save, plot)\n",
    "elif representation.lower() == 'both':\n",
    "    for i in ('BoW', 'TFIDF'):\n",
    "        fit(i, retrain, models, save, plot)\n",
    "else:\n",
    "    raise Exception(\"Selected representation is not in ['Bow', 'TFIDF', 'Both', 'Both']\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
