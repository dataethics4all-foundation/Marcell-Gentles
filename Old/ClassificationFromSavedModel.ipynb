{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16f0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectype = \"TFIDF\"\n",
    "#size = 50\n",
    "#modelPath = os.path.join(cd, rf'{vectype}_{model}_{loadNumber}.pkl')\n",
    "import tweepy as tp\n",
    "import os\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "user = (input(\"Enter your twitter handle here: \")).replace('@', '')\n",
    "#put in choices for retweets and replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff820e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUserInput(username, max_results= 5, includingRetweets = False, includingReplies = True):\n",
    "    bearer_token = \"AAAAAAAAAAAAAAAAAAAAAAcblQEAAAAAtCqsQJwLtdMjU9olMpKT8mYnmjI%3D4707FKE1BToIY6TgtwgVzfNKAv7vohP1Uo3lDubgxwhUalWHi3\"\n",
    "    client_ID = \"bjB6WHYzMlZhc3RYNF84Wlo0amM6MTpjaQ\"\n",
    "    client_secret = \"-ZuUb0O6awVPBJLxGSVv7ezzt0PhxQjeMqaXh6JIJixiNKjGtl\"\n",
    "    redirect_uri = \"https://troy.kli.ng/\"\n",
    "    consumer_key = \"TUMFGbPsKwZ9UmOvJxjTNC2vo\"\n",
    "    consumer_secret = \"pEzDJheRCGab7NG2phj5nnv7y6DovX4Ey9rfbHeqh7tv3t2ysY\"\n",
    "    access_token = \"1615397853140242432-4gubCI7K70hryA84LHtAhmkXigRVAl\"\n",
    "    access_token_secret = \"Z8JYzhlh5eiXkNy6q3oOY9SPEW7jFb62nLKuxf6FBmyGM\"\n",
    "\n",
    "    #authentication\n",
    "    #I have all of these ready to go here, but only ended up needing 'bearer_token'.\n",
    "\n",
    "    client = tp.Client(bearer_token=bearer_token)\n",
    "\n",
    "    ID = client.get_user(username= username).data.id\n",
    "\n",
    "    def add_tweet(tweetData):\n",
    "        tweetList.append((tweetData.id, tweetData.text))\n",
    "\n",
    "    def choose_exclusions(rt, rp):\n",
    "        l = []\n",
    "        if not rt:\n",
    "            l.append('retweets')\n",
    "        if not rp:\n",
    "            l.append('replies')\n",
    "        return l\n",
    "\n",
    "    tweets = client.get_users_tweets(id=ID, max_results=max_results, exclude= choose_exclusions( \\\n",
    "        includingRetweets, includingReplies))\n",
    "\n",
    "    tweetList = []\n",
    "\n",
    "    for i in range(len(tweets.data)):\n",
    "        add_tweet(tweets.data[i])\n",
    "    \n",
    "    return tweetList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3037196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1665451497826537476, '@dayveedlol see this why i dont fw european niggas'), (1665451352812666881, '@tres_manxes thats real'), (1665451318889021442, '@joe3971 indecisive ass nigga'), (1665440070554222594, '@2drowsyy nasty ðŸ˜·'), (1665414960107642880, 'sweaty sex or air conditioner sex')]\n"
     ]
    }
   ],
   "source": [
    "print(GetUserInput('wtfsicckko'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a75fbb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = r\"C:\\Users\\marce\\Project\\models\\TFIDF500\" #whatever model folder i choose\n",
    "modelPath = os.path.join(cd, 'Model_TFIDF_NaiveBayes_500.pkl')\n",
    "vocabPath = os.path.join(cd, 'Vocab_500.pkl')\n",
    "uInput = pd.DataFrame(GetUserInput(user), columns= ['ID', 'Text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e5a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use whichever of these three I decide to joblib load\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2404820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ID                                               Text\n",
      "0  1665451497826537476  @dayveedlol see this why i dont fw european ni...\n",
      "1  1665451352812666881                            @tres_manxes thats real\n",
      "2  1665451318889021442                      @joe3971 indecisive ass nigga\n",
      "3  1665440070554222594                                  @2drowsyy nasty ðŸ˜·\n",
      "4  1665414960107642880                  sweaty sex or air conditioner sex\n"
     ]
    }
   ],
   "source": [
    "print(uInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6f5efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                   ID  \\\n",
      "0      0  1665451497826537476   \n",
      "1      0  1665451352812666881   \n",
      "2      0  1665451318889021442   \n",
      "3      0  1665440070554222594   \n",
      "4      0  1665414960107642880   \n",
      "\n",
      "                                                Text  \\\n",
      "0  @dayveedlol see this why i dont fw european ni...   \n",
      "1                            @tres_manxes thats real   \n",
      "2                      @joe3971 indecisive ass nigga   \n",
      "3                                  @2drowsyy nasty ðŸ˜·   \n",
      "4                  sweaty sex or air conditioner sex   \n",
      "\n",
      "                        Cleaned  \n",
      "0         see fw european nigga  \n",
      "1                          real  \n",
      "2             indecis ass nigga  \n",
      "3                         nasti  \n",
      "4  sweati sex air condition sex  \n",
      "                    ID                                               Text  \\\n",
      "0  1665451497826537476  @dayveedlol see this why i dont fw european ni...   \n",
      "1  1665451352812666881                            @tres_manxes thats real   \n",
      "2  1665451318889021442                      @joe3971 indecisive ass nigga   \n",
      "3  1665440070554222594                                  @2drowsyy nasty ðŸ˜·   \n",
      "4  1665414960107642880                  sweaty sex or air conditioner sex   \n",
      "\n",
      "                        Cleaned  \n",
      "0         see fw european nigga  \n",
      "1                          real  \n",
      "2             indecis ass nigga  \n",
      "3                         nasti  \n",
      "4  sweati sex air condition sex  \n"
     ]
    }
   ],
   "source": [
    "from CleanTweetsScript import CleanDF, vectorize\n",
    "cleaned, vocab = (CleanDF(uInput), load(vocabPath))\n",
    "print(cleaned)\n",
    "#cleaned.drop(labels='index', axis=1, inplace=True)\n",
    "df, _ = vectorize(cleaned, vocab=vocab)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd1faff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3:int((df.shape[1] - 3) / 2)\n",
    "\n",
    "bow_df = df.iloc[:, 3:int((df.shape[1] - 3) / 2 + 3)]\n",
    "bow_df = bow_df.reset_index(drop=True)\n",
    "\n",
    "tfidf_df = df.iloc[:, int((df.shape[1] - 3) / 2 + 3):df.shape[1]]\n",
    "tfidf_df = tfidf_df.reset_index(drop=True)\n",
    "\n",
    "idNum = df.ID.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "398caca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4] Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4] 0    1665451497826537476\n",
      "1    1665451352812666881\n",
      "2    1665451318889021442\n",
      "3    1665440070554222594\n",
      "4    1665414960107642880\n",
      "Name: ID, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(bow_df, tfidf_df, idNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d81ff29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\marce\\miniconda3\\envs\\SiAI\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m load(modelPath)\n\u001b[1;32m----> 2\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(tfidf_df)\n\u001b[0;32m      3\u001b[0m predSeries \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(predictions)\n\u001b[0;32m      4\u001b[0m fullDF \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(predSeries, df\u001b[39m.\u001b[39miloc[:,[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]],axis\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\marce\\miniconda3\\envs\\SiAI\\Lib\\site-packages\\sklearn\\naive_bayes.py:105\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(X)\n\u001b[0;32m    106\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32md:\\Users\\marce\\miniconda3\\envs\\SiAI\\Lib\\site-packages\\sklearn\\naive_bayes.py:579\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    578\u001b[0m     \u001b[39m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Users\\marce\\miniconda3\\envs\\SiAI\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32md:\\Users\\marce\\miniconda3\\envs\\SiAI\\Lib\\site-packages\\sklearn\\utils\\validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    774\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[0;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dtypes_orig\n\u001b[0;32m    776\u001b[0m     )\n\u001b[0;32m    777\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype_iter, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype_iter \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 778\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mresult_type(\u001b[39m*\u001b[39mdtypes_orig)\n\u001b[0;32m    780\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    781\u001b[0m     \u001b[39m# array is a pandas series\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = load(modelPath)\n",
    "predictions = model.predict(tfidf_df)\n",
    "predSeries = pd.Series(predictions)\n",
    "fullDF = pd.concat(predSeries, df.iloc[:,[0,1]],axis= 1)\n",
    "print(fullDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
