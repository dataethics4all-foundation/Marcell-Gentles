{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This program trains a sentiment analyis model (logistic regression or SVM)\n",
    "using TFIDF features. It stores the model, along with some information from\n",
    "its training and some metrics, in the \"models\" folder of this project's\n",
    "directory. There are functions to preprocess text, extract features, train the\n",
    "model, and to save them to a file.\n",
    "\"\"\"\n",
    "\n",
    "# Modules for saving objects.\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# These are used for reading training data.\n",
    "import csv\n",
    "\n",
    "# These are some modules used for preprocessing.\n",
    "from contractions import fix\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# These modules is for extracting features from the data.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# These modules are for training the ML model.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "def now():      # Used by model timelog\n",
    "    return datetime.now().strftime(r'%H:%M:%S.%f')\n",
    "\n",
    "#These modules are used for measuring the model's performance.\n",
    "import sklearn\n",
    "from pandas import Series\n",
    "\n",
    "STOPWORDS = [\n",
    "    'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an',\n",
    "    'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been',\n",
    "    'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\",\n",
    "    'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\",\n",
    "    'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from',\n",
    "    'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having',\n",
    "    'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself',\n",
    "    'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\",\n",
    "    'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\",\n",
    "    'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of',\n",
    "    'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours',\n",
    "    'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\",\n",
    "    \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than',\n",
    "    'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then',\n",
    "    'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\",\n",
    "    \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up',\n",
    "    'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were',\n",
    "    \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which',\n",
    "    'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would',\n",
    "    \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours',\n",
    "    'yourself', 'yourselves'\n",
    "    ]\n",
    "\n",
    "# Placeholders to test my code.\n",
    "MODEL = LogisticRegression\n",
    "\n",
    "# Replace with a get_corpus function that takes in a csv and columns for\n",
    "# documents and labels and reads them to a list of tuples:\n",
    "# [(document, label),...]. Access list of documents using\n",
    "# (p[0] for p in corpus) and list of labels using (p[1] for p in corpus)\n",
    "corpus = [\n",
    "    (\"Hey! I'm Marcell. Nice to meet you.\", 0),\n",
    "    (\"I love my cat very much. He's a cool guy.\", 1),\n",
    "    (\"I love my girlfriend very much. She has pretty brown eyes and skin. Plus, her bottom is gargantuan! I want to put her on https://www.lightskinned.com.\", 1),\n",
    "    (\"Coding is crazy. I've been here for like 2 days straight. Shoutout to JosÃ© Gonzalez.\", 0)\n",
    "    ]\n",
    "\n",
    "# I want a to collect a dictionary like this:\n",
    "#   {\n",
    "# 'corpus': str(corpus name), 'size': int(training size),\n",
    "# 'vectorizer': str(vectorizer), 'time': datetime(time trained)\n",
    "# }.\n",
    "model_info = {\n",
    "    'corpus': str(corpus name), 'size': int(training size),\n",
    "    'vectorizer': str(vectorizer), 'time': datetime(time trained)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(object, path: str, serializer=joblib) -> None:\n",
    "    \"\"\"Takes an object (like a model or vectorizer) to save, a path to save it\n",
    "    to, and a serialization module, and saves the object to disk to be used in\n",
    "    the future. Both pickle and joblib seem to work, but apparently joblib\n",
    "    works better for objects like large numpy arrays like models/vectorizers.\n",
    "    \"\"\"\n",
    "    if serializer == joblib:\n",
    "        joblib.dump(object, path)\n",
    "\n",
    "    elif serializer == pickle:\n",
    "        with open(path, 'wb') as f:     # It's a binary file, not text.\n",
    "            pickle.dump(object, f)\n",
    "\n",
    "    else: raise Exception(\"Serializer must be joblib or pickle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts: list) -> list:\n",
    "    \"\"\"Takes in a list (corpus) of strings and returns a list of the processed\n",
    "    versions of the strings.\n",
    "    \"\"\"\n",
    "    temp = []   # A list that will fill with processed documents.\n",
    "    for s in texts:\n",
    "        \n",
    "        # Normalize diacritics, contractions, and slang.\n",
    "        # The use of contractions and slang could be important, so maybe don't\n",
    "        # use contractions.fix, and make the unidecode slang argument False.\n",
    "        # However, if contractions are used, you might need to add various\n",
    "        # apostrophe forms to the last substitution filter: re.sub('[^'...\n",
    "        s = fix(unidecode(s))\n",
    "        \n",
    "        # Remove the links and @mentions with regular expression substitutions.\n",
    "        s = re.sub(r'@\\w+', '', s)    # Removes @users (\\w is a-Z, 0-9, _).\n",
    "        s = re.sub(r'http\\S+', '', s)\n",
    "        s = re.sub(r'www\\.\\S+', '', s)    # Removes links.\n",
    "        s = re.sub(r'\\s+', ' ', s)  # Removes extra spaces\n",
    "        s = re.sub(r'[^\\w\\s#]', '', s)    # Removes all but abc123... and '#'.\n",
    "\n",
    "        # Stem the words. PorterStemmer.stem() also makes lowercase.\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_words = []      # A list that will fill with stemmed words\n",
    "        for w in s.split():     # on a document level.\n",
    "            if w.lower() not in STOPWORDS:  # Only adds words if meaningful.\n",
    "                stemmed_words.append(stemmer.stem(w))\n",
    "        s = ' '.join(stemmed_words)\n",
    "\n",
    "        temp.append(s)  # Add the processed document to the new corpus.\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Both of these functions are pretty sketchy. They both have pretty short\n",
    "# equivalents and kind of just play with the syntax of the corresponding lines\n",
    "# of code. I should probably use their equivalents (listed in the first line\n",
    "# of each one's docstring) instead.\n",
    "\n",
    "def fit_vectorizer(corpus: list, vectorizer_type=TfidfVectorizer): # I need to get this to the model trainer to save.\n",
    "    \"\"\"Consider using this equivalent instead:\n",
    "    vectorizer_type().transform(corpus).\n",
    "    \\n\n",
    "    Takes in a preprocessed list of strings and fits the specified type of\n",
    "    vectorizer to it. This returns the fitted vectorizer.\n",
    "    \"\"\"\n",
    "    vectorizer = vectorizer_type()  # Create a new instance of the chosen type.\n",
    "    return vectorizer.fit(corpus)\n",
    "\n",
    "def get_features(corpus: list, vectorizer) -> csr_matrix:\n",
    "    \"\"\"Consider using this equivalent instead: vectorizer.transform(corpus).\n",
    "    \\n\n",
    "    Takes in a preprocessed list of strings and extracts each ones's\n",
    "    features using the fitted vectorizer passed in. It returns a scipy\n",
    "    compressed sparse row matrix.\n",
    "    \"\"\"\n",
    "    return vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x: csr_matrix | list) -> list:\n",
    "    \"\"\"Takes in model to be used and a matrix of the corpus' features. The\n",
    "    features must have come from the same vectorizer used to train the model\n",
    "    \"\"\"\n",
    "    return model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, x: csr_matrix | list, y: list,\n",
    "               test_model=None, return_extras: bool = False\n",
    "               ):\n",
    "\n",
    "    \"\"\"Takes in the class of the model to be used, a matrix of the corpus'\n",
    "    features, and a list of the associated given labels. The matrix x can be\n",
    "    sparse or dense eg. DataFrame, numpy.arry, etc. It splits the data\n",
    "    into a set that will train the chosen model and a set that will be used\n",
    "    to test it.\n",
    "    \\n\n",
    "    The model is trained and then saved in the project directory's models\n",
    "    folder along with a timelog of the training, an html table of its testing\n",
    "    stats, plots of its confusion matrices, and the fitted vectorizer used.\n",
    "    By default, this function only returns the trained model, but with\n",
    "    return_extras set to True, it returns the timelog, table, and plots as\n",
    "    well, and saves nothing to disk.\n",
    "    \\n\n",
    "    With a test_model passed, the x and y passed in will not be used to\n",
    "    retrain the model but instead solely to test it.\n",
    "    \"\"\"\n",
    "    if test_model is None:\n",
    "        time_log = [f'{model_info} Time Log:\\n\\n']   # Initialize the log to be filled over time.\n",
    "        time_log.append(f'Began at                  {now()}')\n",
    "        model = model()     # Instantiate the model\n",
    "        time_log.append(f'Model istantiated at      {now()}')\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "        time_log.append(f'Train and test split at   {now()}')\n",
    "        model.fit(x_train, y_train)\n",
    "        time_log.append(f'Model fit at              {now()}')\n",
    "        time_log = '\\n'.join(time_log)  # Make it a readably formatted text.\n",
    "\n",
    "    else:\n",
    "        model = test_model\n",
    "        x_test, y_test = x, y\n",
    "\n",
    "    preds = predict(model, x_test)\n",
    "\n",
    "    \n",
    "    # There are three ways to do this. I can make it with\n",
    "    # ConfusionMatrixDisplay.from_estimator(model, x_test, y_test). This is\n",
    "    # not a good idea because it requires extra computation of using the model\n",
    "    # again in case it's already made predictions. I can also make it using\n",
    "    # ConfusionMatrixDisplay.from_predictions(y_test, preds). This skips the\n",
    "    # intermediate step of actually generating the (numpy) matrix and goes\n",
    "    # straight to a display. The third is to generate a matrix first using\n",
    "    # sklearn.metrics.confusion_matrix(y_test, pred) and then\n",
    "    # sklearn.metrics.ConfusionMatrixDisplay() with that matrix as the arg.\n",
    "    matrix_display = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, preds\n",
    "        )\n",
    "    matrix_display.ax_.set_title(model_info)\n",
    "\n",
    "    # Get some stats of the performance stats of the model.\n",
    "    def metrics(y_true, y_pred):\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "        precision = sklearn.metrics.precision_score(y_true, y_pred)\n",
    "        recall = sklearn.metrics.recall_score(y_true, y_pred)\n",
    "        f1 = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "        return accuracy, precision, recall, f1\n",
    "    \n",
    "    # Make a pandas Series with the scores, then turn it into an html table\n",
    "    # (via DataFrame). The html data is not written to disk, but instead\n",
    "    # becomes a string of html source code (metrics_html). A line of html that\n",
    "    # contains a heading (<h3>) with some information about the training\n",
    "    # process is inserted into the top of the string, so that the html file\n",
    "    # has a description and, under it, a table of scores.\n",
    "    metrics_ser = Series(metrics(y_test, preds),\n",
    "                        index=['Accuracy', 'Precision', 'Recall', 'F1'],\n",
    "                        name='Score'\n",
    "                        )\n",
    "    metrics_html = metrics_ser.to_frame().to_html()\n",
    "    metrics_html = f'<h3>{model_info} Scores</h3>\\n{metrics_html}'\n",
    "\n",
    "    goodies = [\n",
    "        (metrics_html, 'metrics.html'), ()\n",
    "        ]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\marce\\miniconda3\\envs\\SiAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def start(\n",
    "    mode: str, data: list[tuple[str, int]] | list[str], vectorizer, model\n",
    "    ) -> None:\n",
    "    \"\"\"Starts the process of fitting, training, testing, whatever. The\n",
    "    specified mode ([insert modes here]) determines which process(es) it does.\n",
    "    \\n\n",
    "    The modes are:\n",
    "    'fitv' to fit the vectorizer, \n",
    "    'train' to train the model, \n",
    "    'test' to test the model, \n",
    "    'predict' to get predictions from the data, \n",
    "    \n",
    "    You can set use an argument for data that is a list of tuples\n",
    "    (document, label) for a model training mode or testing, or a list of\n",
    "    documents for a model prediction mode.\n",
    "    You can select a vectorizer to use (string 'tfidf' or 'bow' if in a\n",
    "    vectorizer fitting mode, or a fitted vectorizer object if not), a model to\n",
    "    use (string 'nb', 'lr', or 'svm' if in a model fitting mode, or a trained\n",
    "    model object if not)\n",
    "    \"\"\"\n",
    "    mode = mode.lower()\n",
    "    if mode = 'fitv'\n",
    "vec = fit_vectorizer(preprocess(corpus))\n",
    "features = get_features((d[0] for d in corpus), vec)\n",
    "train_test(LogisticRegression, features, (d[1] for d in corpus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SiAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
